# 239-add-recursive-language-models-rlms-demo
### signature:
- status: wait
- issue: 239
- source: github
- url: https://github.com/timcash/dialtone/issues/239
- synced-at: 2026-02-21T19:50:23Z
### sync:
- github-updated-at: 2026-02-10T23:29:26Z
- last-pulled-at: 2026-02-21T19:50:23Z
- last-pushed-at: 
- github-labels-hash: 
### description:
- see https://arxiv.org/pdf/2512.24601
- We study allowing large language models (LLMs)
- to process arbitrarily long prompts through the
- lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general
- inference paradigm that treats long prompts as
- part of an external environment and allows the
- LLM to programmatically examine, decompose,
- and recursively call itself over snippets of the
- prompt. We find that RLMs can successfully
- process inputs up to two orders of magnitude
- beyond model context windows and, even for
- shorter prompts, dramatically outperform the
- quality of vanilla frontier LLMs and common
- long-context scaffolds across four diverse long-
- context tasks while having comparable cost. At
- a small scale, we post-train the first natively
- recursive language model. Our model, RLM-
- Qwen3-8B, outperforms the underlying Qwen3-
- 8B model by 28.3% on average and even ap-
- proaches the quality of vanilla GPT-5 on three
- long-context tasks. Code is available at https:
- //github.com/alexzhang13/rlm.
### tags:
- todo
### comments-github:
- none
### comments-outbound:
- TODO: add a bullet comment here to post to GitHub
### task-dependencies:
### documentation:
### test-condition-1:
- TODO
### test-command:
- TODO
### reviewed:
### tested:
### last-error-types:
### last-error-times:
### log-stream-command:
- TODO
### last-error-loglines:
### notes:
- title: add Recursive Language Models (RLMs) demo
- state: OPEN
- author: timcash
- created-at: 2026-02-10T23:29:26Z
- updated-at: 2026-02-10T23:29:26Z
